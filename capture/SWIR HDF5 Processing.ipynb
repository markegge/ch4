{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this notebook explores working with HDF5 and GOSAT files\n",
    "# to create a binary, refer to capture/GOSAT L2 CH4 to bin.ipynb\n",
    "\n",
    "# TANSO-FTS/GOSAT L2 CH4 column amount (SWIR) product\n",
    "\n",
    "# this cell explores accessing HDF5 attributes.\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "f = h5py.File(\"1606280000-01/1606280000-01/SWIR_L2_CH4_CLMN_V02.60_F150915031133042001/F150915031133042001.h5\", \"r\")\n",
    "print f.name\n",
    "print f.items()\n",
    "print f.keys()\n",
    "print f.values()\n",
    "\n",
    "f.get(\"attribute/imageCorner/upperLeftLongitude\")[0]\n",
    "grp = f.get(\"attribute\")\n",
    "print grp.values()\n",
    "subgrp = grp[\"imageCorner\"]\n",
    "print subgrp.items()\n",
    "def p (x): print x +  \" \" + x[0]\n",
    "subgrp.visit(p)\n",
    "print subgrp[\"upperLeftLongitude\"][0]\n",
    "print subgrp[\"upperLeftLatitude\"][0]\n",
    "print subgrp[\"lowerRightLongitude\"][0]\n",
    "print subgrp[\"lowerRightLatitude\"][0]\n",
    "data = f.get(\"Data\")\n",
    "b1 = data[\"band1Image\"]\n",
    "b1.attrs.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  pretty sure this doesn't work\n",
    "# see GDAL Translate to GTiff.ipynb for working code to clone back here...\n",
    "def convert(inputFile):\n",
    "    f = h5py.File(inputFile, \"r\")\n",
    "    ulx = f.get(\"attribute/imageCorner/upperLeftLongitude\")[0]\n",
    "    uly = f.get(\"attribute/imageCorner/upperLeftLatitude\")[0]\n",
    "    lrx = f.get(\"attribute/imageCorner/lowerRightLongitude\")[0]\n",
    "    lry = f.get(\"attribute/imageCorner/lowerRightLatitude\")[0]\n",
    "  \n",
    "    proj = '-a_srs \"EPSG:4326'\n",
    "    bounds = '-a_ullr %s %s %s %s' % (ulx, uly, lrx, lry)\n",
    "    outputFormat = '-of \"GTiff\"'\n",
    "    inputString = \"'HDF5:\" + '\"' + inputFile + '\"' + \"://Data/band1Image'\"\n",
    "    outputFile = inputFile[:-3] + \"tiff\"\n",
    "    command = 'gdal_translate ' + proj + ' ' + outputFormat + ' ' + bounds + ' ' + \\\n",
    "          + inputString + ' ' + outputFile\n",
    "    print command    \n",
    "    !$command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194L, 4L)\n",
      "[[  1.44228670e+09   5.93873863e+01   1.62880127e+02   1.82433510e+00]\n",
      " [  1.44228677e+09   5.45988770e+01   1.59531479e+02   1.82656777e+00]\n",
      " [  1.44228677e+09   5.45926857e+01   1.59524551e+02   1.82018328e+00]\n",
      " [  1.44228678e+09   5.45882874e+01   1.59519211e+02   1.84255111e+00]\n",
      " [  1.44228684e+09   5.21493454e+01   1.58092834e+02   1.83938289e+00]]\n",
      "[[1442286695.0, 59.387386322021484, 162.880126953125, 1.8243350982666016], [1442286768.0, 54.598876953125, 159.53147888183594, 1.8265677690505981], [1442286773.0, 54.59268569946289, 159.52455139160156, 1.820183277130127], [1442286778.0, 54.588287353515625, 159.5192108154297, 1.8425511121749878], [1442286837.0, 52.14934539794922, 158.09283447265625, 1.8393828868865967]]\n"
     ]
    }
   ],
   "source": [
    "# extracts lat, lon, time, and CH4 value and saves to a csv\n",
    "\n",
    "f = h5py.File(\"c:/Users/markegge/work/ch4/capture/1606280000-01/1606280000-01/GOSATTFTS20150915_02C02SV0260R16062800000.h5\", 'r')\n",
    "numObs = f.get('scanAttribute')['numScan'][0]\n",
    "lats = f.get('Data').get('geolocation')['latitude'][:]\n",
    "lons = f.get('Data').get('geolocation')['longitude'][:]\n",
    "heights = f.get('Data').get('geolocation')['height'][:]\n",
    "xch4s = f.get('Data').get('mixingRatio')['XCH4'][:]\n",
    "times = f.get('scanAttribute')['time'][:]\n",
    "epoch_times = []\n",
    "for f in times:\n",
    "    seconds = int((datetime.strptime(f, '%Y-%m-%d %H:%M:%S.%f') - datetime(1970, 1, 1)).total_seconds())\n",
    "    epoch_times.append(seconds)\n",
    "\n",
    "vals = np.column_stack((epoch_times, lats, lons, xch4s))\n",
    "print vals.shape\n",
    "print vals[0:5]\n",
    "np.savetxt(\"test.csv\", vals, delimiter=\",\", fmt=['%10d', '%3.7f', '%3.7f', '%1.7f'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194L, 4L)\n",
      "(502L, 4L)\n",
      "(849L, 4L)\n",
      "(1215L, 4L)\n",
      "(1602L, 4L)\n",
      "(1943L, 4L)\n",
      "(2331L, 4L)\n",
      "(2733L, 4L)\n",
      "(3050L, 4L)\n",
      "(3343L, 4L)\n",
      "(3648L, 4L)\n",
      "(3865L, 4L)\n",
      "(4130L, 4L)\n",
      "(4410L, 4L)\n",
      "(4744L, 4L)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-234-e38630f8d98a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# lons (x), lats (y), epoch_times (unix epoch), xch4s (ppmv)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"values.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'%10d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%3.7f'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%3.7f'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%1.7f'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gosat.bin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'array' is not defined"
     ]
    }
   ],
   "source": [
    "# extracts lat, lon, time, and CH4 value and saves to a csv and a binary file\n",
    "# that works with the /html/index.html file\n",
    "\n",
    "import array\n",
    "import h5py\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import datetime\n",
    "\n",
    "# set directory containing TANSO-FTS/GOSAT L2 CH4 column amount (SWIR) product files\n",
    "# e.g. \"/Users/markegge/ch4/capture/1606280000-01/1606280000-01/GOSATTFTS20150915_02C02SV0260R16062800000.h5\"\n",
    "\n",
    "root_dir = \"c:/Users/markegge/work/ch4/capture/1606280000-01/1606280000-01\"\n",
    "\n",
    "def read_file(file_path):\n",
    "    f = h5py.File(file_path, 'r')\n",
    "    numObs = f.get('scanAttribute')['numScan'][0]\n",
    "    lats = f.get('Data').get('geolocation')['latitude'][:]\n",
    "    lons = f.get('Data').get('geolocation')['longitude'][:]\n",
    "    heights = f.get('Data').get('geolocation')['height'][:]\n",
    "    xch4s = f.get('Data').get('mixingRatio')['XCH4'][:]\n",
    "    times = f.get('scanAttribute')['time'][:]\n",
    "    epoch_times = []\n",
    "    for f in times:\n",
    "        seconds = int((datetime.strptime(f, '%Y-%m-%d %H:%M:%S.%f') - datetime(1970, 1, 1)).total_seconds())\n",
    "        epoch_times.append(seconds)\n",
    "\n",
    "    vals = np.column_stack((lons, lats, epoch_times, xch4s))\n",
    "    return vals\n",
    "\n",
    "h5files = [f for f in listdir(root_dir) if isfile(join(root_dir, f)) and f[-2:] == 'h5']\n",
    "\n",
    "data = np.empty([1,4])\n",
    "first = True\n",
    "for file in h5files:\n",
    "    if first:\n",
    "        data = read_file(join(root_dir, file))\n",
    "        first = False\n",
    "    else:\n",
    "        data = np.vstack((data, read_file(join(root_dir, file))))\n",
    "    print data.shape\n",
    "\n",
    "# lons (x), lats (y), epoch_times (unix epoch), xch4s (ppmv)\n",
    "np.savetxt(\"values.csv\", data, delimiter=\",\", fmt=['%10d', '%3.7f', '%3.7f', '%1.7f'])  \n",
    "array.array('f', data.toList()).tofile(open('gosat.bin', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194L, 36L)\n",
      "(2L, 194L, 36L)\n",
      "[  59.34601212  162.9564209 ]\n",
      "(194L, 36L, 2L)\n",
      "(6984L, 2L)\n",
      "[[  59.34601212  162.9564209 ]\n",
      " [  59.34058762  162.94187927]\n",
      " [  59.33587265  162.92715454]\n",
      " ..., \n",
      " [  23.37578011 -152.12011719]\n",
      " [  23.36853027 -152.11378479]\n",
      " [  23.36042786 -152.10908508]]\n"
     ]
    }
   ],
   "source": [
    "# extract out the footprints\n",
    "f = h5py.File(\"c:/Users/markegge/work/ch4/capture/1606280000-01/1606280000-01/GOSATTFTS20150915_02C02SV0260R16062800000.h5\", 'r')\n",
    "numObs = f.get('scanAttribute')['numScan'][0]\n",
    "lats = f.get('Data').get('geolocation')['footPrintLatitude'][:,:]\n",
    "print lats.shape\n",
    "lons = f.get('Data').get('geolocation')['footPrintLongitude'][:,:]\n",
    "\n",
    "from datetime import datetime\n",
    "def read_file(file_path):\n",
    "    f = h5py.File(file_path, 'r')\n",
    "    numObs = f.get('scanAttribute')['numScan'][0]\n",
    "    lats = f.get('Data').get('geolocation')['latitude'][:]\n",
    "    lons = f.get('Data').get('geolocation')['longitude'][:]\n",
    "    heights = f.get('Data').get('geolocation')['height'][:]\n",
    "    xch4s = f.get('Data').get('mixingRatio')['XCH4'][:]\n",
    "    times = f.get('scanAttribute')['time'][:]\n",
    "    epoch_times = []\n",
    "    for f in times:\n",
    "        seconds = int((datetime.strptime(f, '%Y-%m-%d %H:%M:%S.%f') - datetime(1970, 1, 1)).total_seconds())\n",
    "        epoch_times.append(seconds)\n",
    "\n",
    "    vals = np.column_stack((lons, lats, epoch_times, xch4s))\n",
    "    return vals\n",
    "\n",
    "vals = np.concatenate((lats, lons)).reshape(2,194,36)\n",
    "print vals.shape\n",
    "print vals[:,0,0]\n",
    "\n",
    "vals2 = np.dstack((lats,lons))\n",
    "print vals2.shape\n",
    "\n",
    "#vals3 = np.split(vals2,[0,0],2)\n",
    "#print len(vals3)\n",
    "#print vals3[2]\n",
    "\n",
    "vals4 = vals2.reshape(194*36,2)\n",
    "print vals4.shape\n",
    "print vals4\n",
    "#print vals\n",
    "\n",
    "np.savetxt(\"footprint-test.csv\", vals4, delimiter=\",\", fmt='%3.6f')\n",
    "#a = np.asarray(vals4)\n",
    "#a.tofile('footprint-test.csv', sep=',', format='%3.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
